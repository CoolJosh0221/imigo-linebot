version: '3.8'
services:
  # Pangolin Tunnel Service (Self-Host Community Edition)
  pangolin:
    image: pangolindev/pangolin:community
    container_name: pangolin
    command:
      - "tunnel"
      - "http"
      - "--url"
      - "http://backend:8000"
      - "--hostname"
      - "${DOMAIN:-}"
    ports:
      - "80:80"
      - "443:443"
    environment:
      - PANGOLIN_TOKEN=${PANGOLIN_TOKEN:-}
      - DOMAIN=${DOMAIN:-}
    depends_on:
      - backend
    restart: unless-stopped
    networks:
      - bot-network

  # FastAPI Backend Service
  backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: migrant-worker-bot
    ports:
      - "8000:8000"
    environment:
      - LINE_CHANNEL_SECRET=${LINE_CHANNEL_SECRET}
      - LINE_CHANNEL_ACCESS_TOKEN=${LINE_CHANNEL_ACCESS_TOKEN}
      - LLM_BASE_URL=http://vllm:8001/v1
      - MODEL_NAME=${MODEL_NAME:-aisingapore/sealion7b-instruct}
      - DATABASE_URL=sqlite+aiosqlite:///data/database.db
      - GOOGLE_MAPS_API_KEY=${GOOGLE_MAPS_API_KEY}
      - DEFAULT_LANGUAGE=${DEFAULT_LANGUAGE:-id}
    volumes:
      - ./data:/data
      - ./config:/app/config:ro
    depends_on:
      - vllm
    restart: unless-stopped
    networks:
      - bot-network

  # vLLM Server for SEA-LION-7B
  vllm:
    image: vllm/vllm-openai:latest
    container_name: vllm
    ports:
      - "8001:8000"
    volumes:
      - ./models:/models
    command:
      - "--model"
      - "/models/sealion-model"
      - "--dtype"
      - "bfloat16" 
      - "--gpu-memory-utilization"
      - "0.85"
      - "--max-model-len"
      - "16384"
      - "--trust-remote-code"
      - "--enforce-eager"
    environment:
      NVIDIA_VISIBLE_DEVICES: all
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    tty: true
    ipc: host
    restart: unless-stopped
    networks:
      - bot-network

networks:
  bot-network:
    driver: bridge