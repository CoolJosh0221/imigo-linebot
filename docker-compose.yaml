version: '3.8'

services:
  # Pangolin Dashboard and API
  pangolin:
    image: docker.io/fosrl/pangolin:latest
    container_name: pangolin
    restart: unless-stopped
    volumes:
      - ./config:/app/config
      - pangolin-data:/var/certificates
      - pangolin-data:/var/dynamic
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/api/v1/"]
      interval: "3s"
      timeout: "3s"
      retries: 15
    networks:
      - bot-network

  # Gerbil WireGuard Tunnel Service
  gerbil:
    image: docker.io/fosrl/gerbil:latest
    container_name: gerbil
    restart: unless-stopped
    depends_on:
      pangolin:
        condition: service_healthy
    command:
      - --reachableAt=http://gerbil:3004
      - --generateAndSaveKeyTo=/var/config/key
      - --remoteConfig=http://pangolin:3001/api/v1/
    volumes:
      - ./config/:/var/config
    cap_add:
      - NET_ADMIN
      - SYS_MODULE
    ports:
      - 51820:51820/udp
      - 21820:21820/udp
      - 443:443
      - 80:80
    networks:
      - bot-network

  # Traefik Reverse Proxy
  traefik:
    image: docker.io/traefik:v3.4.0
    container_name: traefik
    restart: unless-stopped
    network_mode: service:gerbil
    depends_on:
      pangolin:
        condition: service_healthy
    command:
      - --configFile=/etc/traefik/traefik_config.yml
    volumes:
      - ./config/traefik:/etc/traefik:ro
      - ./config/letsencrypt:/letsencrypt
      - pangolin-data:/var/certificates:ro
      - pangolin-data:/var/dynamic:ro

  # FastAPI Backend Service
  backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: migrant-worker-bot
    expose:
      - "8000"
    environment:
      - LINE_CHANNEL_SECRET=${LINE_CHANNEL_SECRET}
      - LINE_CHANNEL_ACCESS_TOKEN=${LINE_CHANNEL_ACCESS_TOKEN}
      - LLM_BASE_URL=http://vllm:8001/v1
      - MODEL_NAME=${MODEL_NAME:-aisingapore/sealion7b-instruct}
      - DATABASE_URL=sqlite+aiosqlite:///data/database.db
      - GOOGLE_MAPS_API_KEY=${GOOGLE_MAPS_API_KEY}
      - DEFAULT_LANGUAGE=${DEFAULT_LANGUAGE:-id}
    volumes:
      - ./data:/data
      - ./config:/app/config:ro
    depends_on:
      - vllm
      - pangolin
    restart: unless-stopped
    networks:
      - bot-network

  # vLLM Server for SEA-LION-7B
  vllm:
    image: vllm/vllm-openai:latest
    container_name: vllm
    ports:
      - "8001:8000"
    volumes:
      - ./models:/models
    command:
      - "--model"
      - "/models/sealion-model"
      - "--dtype"
      - "bfloat16" 
      - "--gpu-memory-utilization"
      - "0.85"
      - "--max-model-len"
      - "16384"
      - "--trust-remote-code"
      - "--enforce-eager"
    environment:
      NVIDIA_VISIBLE_DEVICES: all
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    tty: true
    ipc: host
    restart: unless-stopped
    networks:
      - bot-network

networks:
  bot-network:
    driver: bridge

volumes:
  pangolin-data: